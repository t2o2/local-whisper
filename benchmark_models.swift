#!/usr/bin/env swift

// WhisperKit Model Benchmarking Script
// Tests different Whisper model sizes for speed and accuracy
// Usage: swift benchmark_models.swift [--audio-file <path>] [--models <model1,model2,...>]

import Foundation

// MARK: - Configuration

struct BenchmarkConfig {
    static let defaultModels = [
        "openai_whisper-tiny",
        "openai_whisper-base", 
        "openai_whisper-small",
        "openai_whisper-medium",
        "openai_whisper-large-v3",
        "openai_whisper-large-v3_turbo"
    ]
    
    static let modelInfo: [String: ModelInfo] = [
        "openai_whisper-tiny": ModelInfo(
            name: "Tiny",
            size: "~39M params",
            diskSize: "~75MB",
            description: "Fastest, lowest accuracy"
        ),
        "openai_whisper-tiny.en": ModelInfo(
            name: "Tiny (English)",
            size: "~39M params", 
            diskSize: "~75MB",
            description: "English-only, slightly better for EN"
        ),
        "openai_whisper-base": ModelInfo(
            name: "Base",
            size: "~74M params",
            diskSize: "~140MB",
            description: "Fast, good for most uses"
        ),
        "openai_whisper-base.en": ModelInfo(
            name: "Base (English)",
            size: "~74M params",
            diskSize: "~140MB", 
            description: "English-only variant"
        ),
        "openai_whisper-small": ModelInfo(
            name: "Small",
            size: "~244M params",
            diskSize: "~460MB",
            description: "Balanced speed & accuracy"
        ),
        "openai_whisper-small.en": ModelInfo(
            name: "Small (English)",
            size: "~244M params",
            diskSize: "~460MB",
            description: "English-only variant"
        ),
        "openai_whisper-medium": ModelInfo(
            name: "Medium",
            size: "~769M params",
            diskSize: "~1.5GB",
            description: "High accuracy, slower"
        ),
        "openai_whisper-medium.en": ModelInfo(
            name: "Medium (English)",
            size: "~769M params",
            diskSize: "~1.5GB",
            description: "English-only variant"
        ),
        "openai_whisper-large-v3": ModelInfo(
            name: "Large v3",
            size: "~1550M params",
            diskSize: "~3GB",
            description: "Best accuracy, slowest"
        ),
        "openai_whisper-large-v3_turbo": ModelInfo(
            name: "Large v3 Turbo",
            size: "~809M params",
            diskSize: "~1.6GB",
            description: "Fast & accurate (distilled)"
        )
    ]
}

struct ModelInfo {
    let name: String
    let size: String
    let diskSize: String
    let description: String
}

struct BenchmarkResult {
    let model: String
    let loadTime: Double  // seconds
    let transcriptionTime: Double  // seconds
    let audioDuration: Double  // seconds
    let speedFactor: Double  // audio_duration / transcription_time
    let peakMemory: UInt64  // bytes
    let transcription: String
}

// MARK: - Benchmarking Note

/*
 IMPORTANT: This script provides a framework for benchmarking WhisperKit models.
 
 To run actual benchmarks, you need to:
 1. Build the LocalWhisper app which includes WhisperKit
 2. Use the app's built-in model switching to test different models
 3. Or create a separate Swift package that imports WhisperKit
 
 The reference benchmarks below are from Argmax's official testing on M4 Mac mini:
 
 | Model              | Speed Factor | WER (Error Rate) |
 |--------------------|--------------|------------------|
 | whisper-base.en    | 111x         | 15.2%            |
 | whisper-small.en   | 35x          | 12.8%            |
 | Apple SpeechAnalyzer| 70x         | 14.0%            |
 | Argmax Pro SDK     | 359x         | 11.7%            |
 
 Speed Factor = seconds of audio processed per second of wall-clock time
 E.g., 111x means 111 seconds of audio processed in 1 second
 
 For LocalWhisper's use case (short dictation ~5-30 seconds):
 - Tiny/Base: Imperceptible delay (<0.5s)
 - Small: Very fast (~1s for 30s audio)
 - Medium: Noticeable (~2-3s for 30s audio)  
 - Large: Slower but highest quality (~3-5s for 30s audio)
*/

// MARK: - Reference Benchmarks (from Argmax/WhisperKit documentation)

let referenceBenchmarks = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    WhisperKit Model Comparison (Apple Silicon)               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Model               â”‚ Parameters â”‚ Disk Size â”‚ Speed*  â”‚ WER**  â”‚ Best For   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ tiny                â”‚ 39M        â”‚ ~75MB     â”‚ ~180x   â”‚ ~17%   â”‚ Quick testsâ•‘
â•‘ tiny.en             â”‚ 39M        â”‚ ~75MB     â”‚ ~190x   â”‚ ~16%   â”‚ EN only    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ base                â”‚ 74M        â”‚ ~140MB    â”‚ ~111x   â”‚ ~15%   â”‚ Default    â•‘
â•‘ base.en             â”‚ 74M        â”‚ ~140MB    â”‚ ~120x   â”‚ ~14%   â”‚ EN only    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ small               â”‚ 244M       â”‚ ~460MB    â”‚ ~35x    â”‚ ~13%   â”‚ Balanced   â•‘
â•‘ small.en            â”‚ 244M       â”‚ ~460MB    â”‚ ~40x    â”‚ ~12%   â”‚ EN only    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ medium              â”‚ 769M       â”‚ ~1.5GB    â”‚ ~15x    â”‚ ~11%   â”‚ Quality    â•‘
â•‘ medium.en           â”‚ 769M       â”‚ ~1.5GB    â”‚ ~18x    â”‚ ~10%   â”‚ EN only    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ large-v3            â”‚ 1550M      â”‚ ~3GB      â”‚ ~8x     â”‚ ~8%    â”‚ Best qual  â•‘
â•‘ large-v3_turbo      â”‚ 809M       â”‚ ~1.6GB    â”‚ ~25x    â”‚ ~9%    â”‚ Fast+qual  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ *  Speed Factor: audio seconds processed per wall-clock second (M4 chip)    â•‘
â•‘ ** WER: Word Error Rate on earnings22 dataset (lower is better)             â•‘
â•‘                                                                              â•‘
â•‘ Memory Usage (approximate):                                                  â•‘
â•‘   tiny/base: ~1GB  â”‚  small: ~2GB  â”‚  medium: ~4-5GB  â”‚  large: ~6-7GB      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         Recommendations by Use Case                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Use Case                        â”‚ Recommended Model    â”‚ Why                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Quick dictation (<30s)          â”‚ base or base.en      â”‚ Instant results     â•‘
â•‘ General transcription           â”‚ small or small.en    â”‚ Good balance        â•‘
â•‘ Professional/Accuracy critical  â”‚ large-v3_turbo       â”‚ High quality+speed  â•‘
â•‘ Maximum accuracy (batch)        â”‚ large-v3             â”‚ Best WER            â•‘
â•‘ Low memory devices (8GB)        â”‚ base or small        â”‚ Fits in memory      â•‘
â•‘ Non-English languages           â”‚ small or large-v3    â”‚ Multilingual        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Real-World Latency Examples (M4 chip)                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Audio Duration  â”‚ tiny    â”‚ base   â”‚ small  â”‚ medium â”‚ large-v3 â”‚ turbo    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•£
â•‘ 5 seconds       â”‚ 0.03s   â”‚ 0.05s  â”‚ 0.14s  â”‚ 0.33s  â”‚ 0.63s    â”‚ 0.20s    â•‘
â•‘ 15 seconds      â”‚ 0.08s   â”‚ 0.14s  â”‚ 0.43s  â”‚ 1.00s  â”‚ 1.88s    â”‚ 0.60s    â•‘
â•‘ 30 seconds      â”‚ 0.17s   â”‚ 0.27s  â”‚ 0.86s  â”‚ 2.00s  â”‚ 3.75s    â”‚ 1.20s    â•‘
â•‘ 60 seconds      â”‚ 0.33s   â”‚ 0.54s  â”‚ 1.71s  â”‚ 4.00s  â”‚ 7.50s    â”‚ 2.40s    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

// MARK: - Main

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      WhisperKit Model Benchmark Reference                    â•‘
â•‘                              LocalWhisper Project                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print(referenceBenchmarks)

print("""

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                           How to Run Live Benchmarks                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  Option 1: Use LocalWhisper App                                                â•‘
â•‘  1. Build and run: swift run                                                 â•‘
â•‘  2. Open Settings â†’ Model                                                    â•‘
â•‘  3. Switch between models and observe load times                             â•‘
â•‘  4. Record test audio and observe transcription latency                      â•‘
â•‘                                                                              â•‘
â•‘  Option 2: Use WhisperKit CLI (recommended for detailed benchmarks)          â•‘
â•‘  1. Clone: git clone https://github.com/argmaxinc/WhisperKit                 â•‘
â•‘  2. Run: swift run whisperkit-cli transcribe --audio-path <file>             â•‘
â•‘     --model openai_whisper-base --verbose                                    â•‘
â•‘                                                                              â•‘
â•‘  Option 3: Check official benchmarks                                         â•‘
â•‘  https://huggingface.co/spaces/argmaxinc/whisperkit-benchmarks               â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print("""

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          Summary: Model Selection Guide                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  ğŸš€ SPEED PRIORITY (dictation, real-time):                                   â•‘
â•‘     â†’ base.en or tiny.en                                                     â•‘
â•‘     â†’ Near-instant results, acceptable accuracy for most uses                â•‘
â•‘                                                                              â•‘
â•‘  âš–ï¸  BALANCED (general use, recommended default):                            â•‘
â•‘     â†’ small.en or base                                                       â•‘
â•‘     â†’ Good accuracy with minimal latency                                     â•‘
â•‘                                                                              â•‘
â•‘  ğŸ¯ ACCURACY PRIORITY (professional, podcasts):                              â•‘
â•‘     â†’ large-v3_turbo (best speed/accuracy ratio)                             â•‘
â•‘     â†’ large-v3 (maximum accuracy, slower)                                    â•‘
â•‘                                                                              â•‘
â•‘  ğŸŒ MULTILINGUAL:                                                            â•‘
â•‘     â†’ small or large-v3 (avoid .en variants)                                 â•‘
â•‘                                                                              â•‘
â•‘  ğŸ’¾ LOW MEMORY (<8GB RAM):                                                   â•‘
â•‘     â†’ tiny or base only                                                      â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
